{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG file parsing for gene names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_gene_id(name):\n",
    "    if name.startswith('FRAX'):  # not FRAEX for excelsior\n",
    "        return name[name.find('_')+1:name.rfind(' ')]\n",
    "    if name.startswith('FRAEX'):\n",
    "        return name[0:name.rfind(' ')]\n",
    "    else:\n",
    "        return name\n",
    "assert convert_to_gene_id(\"FRAX01_FRAEX38873_V2_000052990.1_R0 [FRAX27_predicted_proteins_with_species_tag]\") == \"FRAEX38873_V2_000052990.1_R0\"\n",
    "tomato = 'Solyc03g095770.2.1 pacid=36135394 transcript=Solyc03g095770.2.1 locus=Solyc03g095770.2 ID=Solyc03g095770.2.1.ITAG2.4 annot-version=ITAG2.4 [Slycopersicum_390_ITAG2]'\n",
    "assert convert_to_gene_id(tomato) == tomato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16539"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_HOGs_from_fasta_directory():\n",
    "    directory_HOGs = r\"D:\\josiah\\Documents\\Research\\Thesis - Genome Symmetry\\DNA_Duplications\\data\\HOGFasta\"\n",
    "    from glob import glob\n",
    "    from os.path import join, splitext, basename\n",
    "    file_list = glob(join(directory_HOGs, \"*.fa\"))\n",
    "    HOGs = {}\n",
    "    for filename in file_list:\n",
    "        assert basename(filename).startswith('HOG')\n",
    "        headers = []\n",
    "        with open(filename, 'r') as fasta:\n",
    "            for line in fasta:\n",
    "                if line.startswith('>'):\n",
    "                    headers.append(convert_to_gene_id(line[1:-1]))\n",
    "        #assert len(headers) == len(set(headers)), \"There was a redundant gene mention %s\" % headers \n",
    "        HOGs[basename(splitext(filename)[0])] = headers\n",
    "    return HOGs\n",
    "HOGs = parse_HOGs_from_fasta_directory()\n",
    "len(HOGs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFF parsing for overlapping annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy merge algorithm\n",
    " ( agglomerative clustering? )\n",
    "* Starting clusters can be HOGs\n",
    "* clusters = dict{ gene: pointer to cluster }\n",
    "* Clusters are set(gene)\n",
    "* First gene gets a new cluster\n",
    "* If gene A overlaps with gene B anywhere, then go through each cluster to find gene A and add gene B\n",
    "* If gene B is in any other clusters, find it and merge the entire cluster into gene A cluster\n",
    "* Assert a gene can only ever be in one cluster at a time, except in the atomic operation of merging two\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting from HOGs but no side-effects, using networkx to retreive clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python Network Graphs](https://www.python.org/doc/essays/graphs/)\n",
    "\n",
    "[Creating a networkx graph](https://networkx.github.io/documentation/networkx-1.10/tutorial/tutorial.html)  \n",
    "[Graph Connected Components](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.components.connected.connected_components.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gene1': {'HOG1'}, 'gene2': {'HOG2', 'HOG1'}, 'gene3': {'HOG2'}} \n",
      " {'gene1': {'HOG1'}, 'gene2': {'HOG2', 'HOG1'}, 'gene3': {'HOG2'}}\n"
     ]
    }
   ],
   "source": [
    "def map_genes_to_HOGs(HOGs):\n",
    "    genes_to_HOGs = {}\n",
    "    for hog, genes in HOGs.items():\n",
    "        for gene in genes:\n",
    "            if gene not in genes_to_HOGs:\n",
    "                genes_to_HOGs[gene] = set()\n",
    "            genes_to_HOGs[gene].add(hog)\n",
    "    return genes_to_HOGs\n",
    "\n",
    "def test_map_genes_to_HOGs():\n",
    "    genes_to_HOGs_answer = {'gene1': {'HOG1'},\n",
    "                     'gene2': {'HOG1', 'HOG2'},\n",
    "                     'gene3': {'HOG2'}}\n",
    "    HOGs = {'HOG1': set(('gene1', 'gene2')),\n",
    "            'HOG2': set(('gene2', 'gene3'))}  # all HOGs start out parsed and non-exlusive\n",
    "    genes_to_HOGs = map_genes_to_HOGs(HOGs)\n",
    "    print(genes_to_HOGs, '\\n',genes_to_HOGs_answer)\n",
    "    assert genes_to_HOGs == genes_to_HOGs_answer\n",
    "test_map_genes_to_HOGs()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import networkx\n",
    "\n",
    "def create_cluster_network(genes_to_HOGs, HOGs):\n",
    "    g = networkx.Graph()\n",
    "    g.add_nodes_from(HOGs.keys())\n",
    "    for gene, hogs in genes_to_HOGs.items():\n",
    "        if len(hogs) > 1:\n",
    "            # two HOGs have overlap and need to be merged\n",
    "            g.add_edges_from(combinations(hogs, 2))  # add edge between all hogs\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HOG1-HOG2': {'gene1', 'gene2', 'gene3'}}\n"
     ]
    }
   ],
   "source": [
    "def make_super_HOGs(HOGs, networked_hogs):\n",
    "    \"\"\"collect subnetworks together into larger clusters\"\"\"\n",
    "    super_HOGs = {}\n",
    "    genes_seen = set()\n",
    "    clusters = [c for c in sorted(networkx.connected_components(networked_hogs), key=len, reverse=True)]\n",
    "    for cluster in clusters:\n",
    "        name = '-'.join(cluster)\n",
    "        super_HOGs[name] = set().union(gene for hog in cluster for gene in HOGs[hog])\n",
    "        assert super_HOGs[name] not in genes_seen, \"You missed a clustering connection.  Genes should only occur once\"\n",
    "        genes_seen.update(super_HOGs[name])\n",
    "            \n",
    "    return super_HOGs\n",
    "\n",
    "def test_make_super_HOGs():\n",
    "    super_HOGs_answer = {'HOG1-HOG2': {'gene1','gene2','gene3'}}\n",
    "    HOGs = {'HOG1': set(('gene1', 'gene2')),\n",
    "            'HOG2': set(('gene2', 'gene3'))}  # all HOGs start out parsed and non-exlusive\n",
    "    genes_to_HOGs = map_genes_to_HOGs(HOGs)\n",
    "    network = create_cluster_network(genes_to_HOGs, HOGs)\n",
    "    assert str(network.edges()) == \"[('HOG1', 'HOG2')]\", network.edges()\n",
    "    super_HOGs = make_super_HOGs(HOGs, network)\n",
    "    print(super_HOGs)\n",
    "    assert super_HOGs == super_HOGs_answer, super_HOGs\n",
    "test_make_super_HOGs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Clusters with Real HOGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_genes_to_HOGs = map_genes_to_HOGs(HOGs)\n",
    "actual_network = create_cluster_network(actual_genes_to_HOGs, HOGs)\n",
    "super_HOGs = make_super_HOGs(HOGs, actual_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(super_HOGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "largest_cc = max(networkx.connected_components(actual_network), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOG27342-HOG25547-HOG9983-HOG27399-HOG2766-HOG27814-HOG2765-HOG2763'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_super = '-'.join(largest_cc)\n",
    "big_super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FRAEX38873_V2_000009700.1_R0',\n",
       " 'FRAEX38873_V2_000287630.1_R0',\n",
       " 'FRAEX38873_V2_000292080.1_R0',\n",
       " 'FRAEX38873_V2_000370050.1_R0',\n",
       " 'FRAEX38873_v2_000009700.1 gene=FRAEX38873_v2_000009700',\n",
       " 'FRAEX38873_v2_000370050.1 gene=FRAEX38873_v2_000370050',\n",
       " 'OE6A037693P1 [OE6A]',\n",
       " 'OE6A045665P1 [OE6A]',\n",
       " 'OE6A100831P1 [OE6A]'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_HOGs[big_super]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp HOG27342.fa ../super_hog_test_viz/\n",
      "cp HOG25547.fa ../super_hog_test_viz/\n",
      "cp HOG9983.fa ../super_hog_test_viz/\n",
      "cp HOG27399.fa ../super_hog_test_viz/\n",
      "cp HOG2766.fa ../super_hog_test_viz/\n",
      "cp HOG27814.fa ../super_hog_test_viz/\n",
      "cp HOG2765.fa ../super_hog_test_viz/\n",
      "cp HOG2763.fa ../super_hog_test_viz/\n"
     ]
    }
   ],
   "source": [
    "for f in big_super.split('-'):\n",
    "    print(\"cp %s.fa ../super_hog_test_viz/\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([c for c in sorted(networkx.connected_components(actual_network), key=len, reverse=True) if len(c) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* output files with lists of gene names to look for in each HOG\n",
    "* per species, find those gene names in the annotation\n",
    "* count presence / absence of a gene name in an annotation\n",
    "* group them back by super-HOGs\n",
    "* End result: gene copy count per each gene family defined by a super-HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Should I call this a multigene family?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
